---
title: "|  Data Analysis (RAD-seq) - *Ficus*  |"
---

*This is a Quarto website. To learn more about Quarto websites visit <https://quarto.org/docs/websites>.*

## Some notes to begin with

-   You might want to edit the installation scripts to fit

i)  your system (Linux vs Mac)
ii) the version of the software (latest for August 2022 documented here).

-   Depending on your system, you can run a script using (for example):

`sbatch my_script.sh` (if your HPC system is using the slurm workload manager). To check status of your job, run (for example): `squeue --user=yourname --long`

`sh my_script.sh` (for a usual script run)

-   If you are working on a Mac OS, use this command when downloading through url links instead of the wget command:

`curl -O url.link`

-   If you have the programs already installed, feel free to adjust your code to simplify the script.

-   To ensure your scripts are executable, change the permissions by running: `chmod a+x script.sh`

-   Always check the terminal output (or slurm-job.out file)!

-   Sadly, Stacks is very tricky to install in a Mac. You might want to consider doing the analysis in a Linux environment instead.

## 1) The environment

To ensure this pipeline will work on your system, you need to have the same environment setup as the one described here. For a start, in your current folder = directory (I called this **fig_analysis**) you need:

i)  one folder with your raw data (fastq.gz), named **raw_data**. You can create this directory by running:

`mkdir raw_data`

Then, upload/transfer your data in this directory. You can do this by running (for example in my case):

`scp 784*fastq.gz sotiriaboutsi@cyverse.warwick.ac.uk:/home/sotiriaboutsi/fig_analysis/raw_data`

ii) one folder with the required software (we will install as we go). You can create this directory by running:

`mkdir software`

## 2) The data

Our data are single-end RAD-seq reads, demultiplexed by SNPSaurus (separate files for each run per sample) and have a single index barcode (no inline barcode in sequence, no need to trim).

Each sample has reads from multiple runs. To view first 10 lines of the data, you can run:

`zcat ./raw_data/filename.gz | head -10`

Keep in mind that this will not work in a Mac OS operating system.

## 3) Quality control of the data

We will run fastqc for the raw reads to get an idea of the sample quality.

### 3.1) Installing fastqc

To install fastqc, you can run the [fastqc_intall_linux.sh](%22/Users/u2095750/Documents/GitHub/website/docs/script%20files/fastqc_intall_linux.sh%22) script, *or* run the following commands:

`wget  -P ./software https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.9.zip --no-check-certificate`

`unzip ./software/fastqc_v0.11.9.zip` `mv FastQC software` `chmod a+x ./software/FastQC/fastqc`

### 3.2) Running fastqc

You can now run fastqc in your raw data by running the [fastqc.sh](%22/Users/u2095750/Documents/GitHub/website/docs/script%20files/fastqc.sh%22) script *or* by running:

`for i in ./raw_data/*.fastq.gz` `do` `./software/FastQC/fastqc ${i}` `done`

You can now make a new folder called **fastqc_results** and move there the results of the fastqc analysis:

`mkdir fastqc_results` `mv ./raw_data/*fastqc* ./fastqc_results`

You can then download the .html files and open for inspection. To download the files to your local machine, you can use (for example):

`scp sotiriaboutsi@cyverse.warwick.ac.uk:/home/sotiriaboutsi/fig_analysis/fastqc_results/"*"html .`

To download the entire directory to your local machine, you can use (for example):

`scp -r sotiriaboutsi@cyverse.warwick.ac.uk:/home/sotiriaboutsi/fig_analysis/fastqc_results .`

## 4) Merging read files from the same sample

Since each sample has reads in multiple runs, I merge the raw files to a single file for each sample. To do this, I need to match all the relevant radtags to the right sample based on the key file provided by SNPSaurus (you can have a look at the key file here: [fig1617_key.txt](%22/Users/u2095750/Documents/GitHub/website/docs/data%20files/fig1617_key.txt%22)) Due to the relative complexity of the matching (radtags are shared across runs) I will do this manually to ensure there are no mistakes, so there is no shortcut or for-loop possible for this step. You can decide to exclude some raw reads file if the quality is bad.

First, I create a folder for the coming merged files:

`mkdir raw_data_per_sample`

Then I run the script merging_data.sh (you can find it here:[merging_data.sh](%22/Users/u2095750/Documents/GitHub/website/docs/script%20files/merging_data.sh%22)) which replicates this type of command for each sample:

`cat ./raw_data/raw_file_1.fastq.gz ./raw_data/raw_file_2.fastq.gz > ./raw_data_per_sample/sample_name.gz`

After this step, you might want to free space by removing the raw reads. **Be careful and make sure you do not need them anymore, as uploading again will be a big waste of time!**

`rm -r raw_reads`

We should now gunzip the compressed files to feed them to the alignment tool. This takes a lot of storage, so ensure you have enough space in your device.

`gunzip ./raw_data_per_sample/*`

## 5) Mapping RAD reads on the reference genome

Now my raw rad data are ready to be aligned to the reference genome, one sample at the time. First I need to install the alignment tool of my choice. I use bowtie2. (Bowtie2 is already pre-installed in cyverse for me.)

### 5.1) Installing bowtie2

If you need to install bowtie2, you need to run the bowtie2_install_linux.sh script ([bowtie2_install_linux.sh](%22/Users/u2095750/Documents/GitHub/website/docs/script%20files/bowtie2_install_linux.sh%22)) *or* the bowtie2_install_mac.sh script ([bowtie2_install_mac.sh](%22/Users/u2095750/Documents/GitHub/website/docs/script%20files/bowtie2_install_mac.sh%22)) script *or* run the following commands:

`wget  -P ./software https://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.4.5/bowtie2-2.4.5-linux-x86_64.zip --no-check-certificate`

`unzip ./software/bowtie2-2.4.5-linux-x86_64.zip` `mv bowtie2-2.4.5-linux-x86_64 software`

### 5.2) Downloading the reference genome

After installation, you can prepare for the alignment.

`mkdir reference`

Download the reference genome (one file for whole genome and one file for cds regions only) by running reference_download.sh script ([reference_download.sh](%22/Users/u2095750/Documents/GitHub/website/docs/script%20files/reference_download.sh%22)) *or* by running:

`wget  -P ./reference https://ftp.cngb.org/pub/CNSA/data3/CNP0000674/CNS0327487/CNA0019284/Fpum.genome.fa.gz --no-check-certificate`

`wget  -P ./reference https://ftp.cngb.org/pub/CNSA/data3/CNP0000674/CNS0327487/CNA0019284/Fpum.genome.cds.fa.gz --no-check-certificate`

### 5.3) Indexing the reference genome

First step is to index the reference genome. Run reference_index.sh ([reference_index.sh](%22/Users/u2095750/Documents/GitHub/website/docs/script%20files/reference_index.sh%22)) *or* reference_index_mac.sh ([reference_index_mac.sh](%22/Users/u2095750/Documents/GitHub/website/docs/script%20files/reference_index_mac.sh%22)) *or* run the following commands:

`./software/bowtie2-2.4.5-linux-x86_64/bowtie2-build -f ./reference/Fpum.genome.fa.gz index_pum`

`./software/bowtie2-2.4.5-linux-x86_64/bowtie2-build -f ./reference/Fpum.genome.cds.fa.gz index_cds_pum`

`mv index* ./reference`

Now we are ready to align our short reads to the reference.

### 5.4) Running bowtie2

I use default parameters as they seem to work okay for my analysis. First, make a folder for results:

`mkdir alignment_results`

Use the alignment_wg.sh ([alignment_wg.sh](%22/Users/u2095750/Documents/GitHub/website/docs/script%20files/alignment_wg.sh%22)) and alignment_cds.sh ([alignment_cds.sh](%22/Users/u2095750/Documents/GitHub/website/docs/script%20files/alignment_cds.sh%22)) scripts *or* run the following commands:

`for i in ./raw_data_per_sample/*.fastq` `do` `echo ${i}` `./software/bowtie2-2.4.5-linux-x86_64/bowtie2 -x ./reference/index_pum -U ${i} -S ${i}_wg.sam` `done`

`mv ./raw_data_per_sample/*.sam ./alignment_results`

`for i in ./raw_data_per_sample/*.fastq` `do` `echo ${i}` `./software/bowtie2-2.4.5-linux-x86_64/bowtie2 -x ./reference/index_cds_pum -U ${i} -S ${i}_cds.sam` `done`

`mv ./raw_data_per_sample/*.sam ./alignment_results`

**! Do NOT delete the slurm-out files from these jobs! Alternatively, save the terminal output: this gives you information on the alignment details.**

We will also need to generate the .bam files and index them.

### 5.5) Install samtools

First we need to install samtools. Run the samtools_install.sh script ([samtools_install.sh](%22/Users/u2095750/Documents/GitHub/website/docs/script%20files/samtools_install.sh%22)) *or* run:

`wget -P ./software https://github.com/samtools/samtools/releases/download/1.3.1/samtools-1.3.1.tar.bz2 -O samtools.tar.bz2` `tar -xjvf ./software/samtools.tar.bz2` `cd ./software/samtools-1.3.1` `make` `cd ..`

### 5.6) Convert .sam to .bam and index .bam files

Make .bam files and index them by running the samtools.sh ([samtools.sh](%22/Users/u2095750/Documents/GitHub/website/docs/script%20files/samtools.sh%22)) script, *or* samtools_mac.sh [samtools_mac.sh](./docs/script files/samtools_mac.sh) (if samtools is preinstalled in your local machine in any path) *or* the following commands:

`for i in ./alignment_results/*.sam` `do` `./software/samtools-1.3.1/samtools sort -o ${i}.bam ${i}` `done`

`for i in ./alignment_results/*.bam` `do` `./software/samtools-1.3.1/samtools index ${i}` `done`

## 6) SNP calling and Fstatistics

Once the raw data are mapped onto a reference genome, we can run the stacks pipeline. We are using ref_map.pl since our reads have been aligned based on a reference genome.

### 6.1) Installing Stacks

First we need to install stacks (you need to adjust to your directory/system).

*This is very tricky to do in a Mac, I haven't figured out how to install it properly! I did my analysis in the cyverse.*

Run:

`wget  -P ./software http://creskolab.uoregon.edu/stacks/source/stacks-2.62.tar.gz --no-check-certificate` `tar -vxf ./software/stacks-2.62.tar.gz` `mv stacks-2.62 software` `cd software/stacks-2.62` `scl enable devtoolset-8 bash` `./configure --prefix /home/sotiriaboutsi` `make` `make install` `cd ..` `cd ..`

### 6.2) Preparing the environment

To run the analysis, you need to upload the "population map" .txt files in the *fig_analysis* directory. These files will match the sample names to their assigned population/species. The number (3 or 4) indicates whether data from *F.trichocerasa* have been included (useful as an outgroup).

The files:

i)  whole genome alignments: [wg_3\_populations.txt](%22/Users/u2095750/Documents/GitHub/website/docs/data%20files/wg_3_populations.txt%22) [wg_4\_populations.txt](%22/Users/u2095750/Documents/GitHub/website/docs/data%20files/wg_4_populations.txt%22) [wg_3\_species.txt](%22/Users/u2095750/Documents/GitHub/website/docs/data%20files/wg_3_species.txt%22) [wg_4\_species.txt](%22/Users/u2095750/Documents/GitHub/website/docs/data%20files/wg_4_species.txt%22)

ii) cds alignments: [cds_3\_populations.txt](%22/Users/u2095750/Documents/GitHub/website/docs/data%20files/cds_3_populations.txt%22)
[cds_4\_populations.txt](%22/Users/u2095750/Documents/GitHub/website/docs/data%20files/cds_4_populations.txt%22)
[cds_3\_species.txt](%22/Users/u2095750/Documents/GitHub/website/docs/data%20files/cds_3_species.txt%22)
[cds_4\_species.txt](%22/Users/u2095750/Documents/GitHub/website/docs/data%20files/cds_4_species.txt%22)
